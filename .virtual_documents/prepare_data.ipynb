in_colab = False
try:
    import google.colab
    in_colab = True
except:
    in_colab = False
in_colab


if in_colab:
  !pip install neurokit2
  !pip install torchinfo
  !pip install pytorch_lightning
  !pip install wfdb
  #!pip install ssqueezepy
  !pip install pycwt
  #!pip install matplotlib==3.8
  #!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118


import torch
from torch import optim, nn
from IPython.display import clear_output
from torchinfo import summary
import neurokit2 as nk
from sklearn.decomposition import PCA
from plotly import graph_objects as go
import os
#import pywt as pw
from math import ceil
import cv2
from matplotlib import cm
from matplotlib import rcParams
import pytorch_lightning as pl
import imageio
import gc
import collections
from pytorch_lightning.loggers import Logger
from pytorch_lightning.loggers.logger import rank_zero_experiment
from pytorch_lightning.utilities import rank_zero_only
import scipy
import pandas as pd
import wfdb
import matplotlib.pyplot as plt
import ast
import os
import warnings
import numpy as np
import math
from torch.utils.data import DataLoader, Dataset
import cv2 as cv
from scipy.signal import butter, lfilter, iirnotch

gc.collect()
with torch.no_grad():
    torch.cuda.empty_cache()

warnings.simplefilter(action='ignore', category=FutureWarning)
rcParams['font.weight'] = 'bold'
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"


channels = ["I", "II", "III", "aVL", "aVR", "aVF", "V1", "V2", "V3", "V4", "V5", "V6" ]
channels_map = {idx: channel for idx, channel in enumerate(channels)}


!python --version


torch.__version__


torch.cuda.is_available()


device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")


%matplotlib inline


map_superclass_rev = {'CD': 0, 'HYP': 1, 'MI': 2, 'NORM': 3, 'STTC': 4}


if in_colab:
  from google.colab import drive
  drive.mount("/content/drive/", force_remount = True)
  %cd "drive/MyDrive/Colab Notebooks/ECG_SuperResolution"


cwd = os.getcwd() + os.sep
path = cwd+"data"+os.sep+"PTB-XL"+os.sep #your dataset path here
filename = path + "ptbxl_database.csv"
df = pd.read_csv(filename, sep=",", index_col="ecg_id")
df.head(20)


n, m = df.shape
n, m


columns = df.columns
map_columns = {column: i for i, column in enumerate(columns)}
map_columns


files =  list(df["filename_hr"].values)


noisy_files = []
for i in range(n):

    print(i , end=" \r")
    row = df.iloc[i, :]
    filenamehr = row["filename_hr"]
    baselinedrift = row["baseline_drift"]
    staticnoise = row["static_noise"]
    electrodesproblems = row["electrodes_problems"]
    burstnoise = row["burst_noise"]
    if isinstance(baselinedrift, str) or isinstance(staticnoise, str)  or isinstance(electrodesproblems, str)  or isinstance(burstnoise, str):
        #print(baselinedrift, type(baselinedrift), staticnoise, type(staticnoise))
        noisy_files.append(filenamehr)


len(noisy_files)


files_no_noise = np.setdiff1d(files, noisy_files)
files_no_noise


seconds = 10
nchs = 12
fs_lr = 100
fs_hr = 500
lenght_lr = fs_lr*seconds
lenght_hr = fs_hr*seconds


len(files_no_noise)


newdf = df.copy()
for file in noisy_files:
    newdf = newdf[newdf["filename_hr"] != file]


newdf.head(10)


cleanrecords_hr = newdf["filename_hr"]
cleanrecords_lr = newdf["filename_lr"]

data_lr = load_raw_data(newdf, fs_lr, path)
data_hr = load_raw_data(newdf, fs_hr, path)


n = len(data_lr)#or hr
data_lr_tensor = torch.zeros((n, nchs, lenght_lr))
data_hr_tensor = torch.zeros((n, nchs, lenght_hr))
for i in range(n):
    print(i+1, "/", n, end=" \r")
    for j in range(nchs):
        temp_data_lr = torch.from_numpy(data_lr[i, j, :])
        temp_data_hr = torch.from_numpy(data_hr[i, j, :])
        data_lr_tensor[i, j, :] = temp_data_lr
        data_hr_tensor[i, j, :] = temp_data_hr


# load and convert annotation data
Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')
Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))

# Load raw signal data
X = load_raw_data(Y, 100, path)
X_hr = load_raw_data(Y, 500, path)

# Load scp_statements.csv for diagnostic aggregation
agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)
agg_df_diagnostic = agg_df[agg_df.diagnostic == 1]
agg_df_notdiagnostic = agg_df[agg_df.diagnostic != 1]

def aggregate_diagnostic(y_dic):
    tmp = []
    for key in y_dic.keys():
        if key in agg_df_diagnostic.index:
            tmp.append(agg_df_diagnostic.loc[key].diagnostic_class)
            break
    return list(set(tmp))

def aggregate_subclass(y_dic):
    tmp = []
    for key in y_dic.keys():
        if key in agg_df_diagnostic.index:
            tmp.append(agg_df_diagnostic.loc[key].diagnostic_subclass)
            break
    return list(set(tmp))

def aggregate_nondiagnostic(y_dic):
    tmp = []
    for key in y_dic.keys():
        if key in agg_df_notdiagnostic.index:
            tmp.append(key)
            break
    return list(set(tmp))

# Apply diagnostic superclass
Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)
Y['diagnostic_subclass'] = Y.scp_codes.apply(aggregate_subclass)
Y['nondiagnostic_class'] = Y.scp_codes.apply(aggregate_nondiagnostic)


uqs, cnts = np.unique(Y['diagnostic_superclass'], return_counts = True)
for i, uq in enumerate(uqs):
    cnt = cnts[i]
    print(uq, ": ", cnt)


uqs, cnts = np.unique(Y['diagnostic_subclass'], return_counts = True)
for i, uq in enumerate(uqs):
    cnt = cnts[i]
    print(uq, ": ", cnt)


uqs, cnts = np.unique(Y['nondiagnostic_class'], return_counts = True)
for i, uq in enumerate(uqs):
    cnt = cnts[i]
    print(uq, ": ", cnt)


# Split data into train and test
gc.collect()
torch.cuda.empty_cache()

test_fold = 10
# Train
X_train = X[np.where(Y.strat_fold != test_fold)]
X_train_hr = X_hr[np.where(Y.strat_fold != test_fold)]
y_train = Y[(Y.strat_fold != test_fold)].diagnostic_superclass
y_train_sub = Y[Y.strat_fold != test_fold].diagnostic_subclass
# Test
X_test = X[np.where(Y.strat_fold == test_fold)]
X_test_hr = X_hr[np.where(Y.strat_fold == test_fold)]
y_test = Y[Y.strat_fold == test_fold].diagnostic_superclass
y_test_sub = Y[Y.strat_fold == test_fold].diagnostic_subclass


Y.strat_fold


signal = X_test[0]
signal_hr = X_test_hr[0]
fig, axs = plt.subplots(2, 1, figsize = (10, 8))
axs[0].plot(signal[0, :], "g")
axs[1].plot(signal_hr[0, :], "b")


from scipy import interpolate


plt.figure(figsize = (20, 10))

idx = 100
signal = X_test[idx]
signal_hr = X_test_hr[idx]
ch = 0
signal_ch = signal[ch]
signal_hr_ch = signal_hr[ch]


print(signal.shape)
fs_lr = 100
fs_hr = 500
t_low_res = np.arange(0, 10, 1/fs_lr)
t_high_res = np.arange(0, 10, 1/fs_hr)  # 500 Hz sampling rate

f_interp = interpolate.interp1d(t_low_res, signal_ch, kind="cubic", fill_value="extrapolate")
signal_up_ch = f_interp(t_high_res)

plt.plot(signal_up_ch, label = "LR")
plt.plot(signal_hr_ch, label = "HR")
plt.legend()


y_train.shape, y_train_sub.shape


X_test.shape, X_test_hr.shape


temp = []
idx_to_remove = []
for i, elem in enumerate(y_train):
    print(i+1, "/", len(list(y_train)), end="\r")
    if len(elem)>0:
        temp.append(elem[0])
    else:
        idx_to_remove.append(i)

X_train = X_train[~np.isin(np.arange(X_train.shape[0]), idx_to_remove)]
X_train_hr = X_train_hr[~np.isin(np.arange(X_train_hr.shape[0]), idx_to_remove)]
y_train_sub = y_train_sub[~np.isin(np.arange(y_train_sub.size), idx_to_remove)]
y_train = np.array(temp)


y_train_sub[:5]


y_train_sub = [y[0] for y in y_train_sub]
y_train_sub[:5]


temp = []
idx_to_remove = []
for i, elem in enumerate(y_test):
    print(i+1, "/", len(list(y_test)), end="\r")
    if len(elem)>0:
        temp.append(elem[0])
    else:
        idx_to_remove.append(i)

X_test = X_test[~np.isin(np.arange(X_test.shape[0]), idx_to_remove)]
X_test_hr = X_test_hr[~np.isin(np.arange(X_test_hr.shape[0]), idx_to_remove)]
y_test_sub = y_test_sub[~np.isin(np.arange(y_test_sub.size), idx_to_remove)]
y_test = np.array(temp)


y_test_sub


y_test_sub = [y[0] for y in y_test_sub]
y_test_sub[:5]


len(idx_to_remove)


y_train_uq = np.unique(y_train)
y_train_uq


map_superclass = {}
for i, uq in enumerate(y_train_uq):
    map_superclass[int(i)] = uq
    y_train[y_train == uq] = int(i)


y_train[:5]


map_superclass


y_train_sub = np.array(y_train_sub)
y_test_sub = np.array(y_test_sub)
y_train_sub_uq = np.unique(y_train_sub)
y_train_sub_uq


map_subclass = {}
for i, uq in enumerate(y_train_sub_uq):
    map_subclass[int(i)] = uq
    y_train_sub[y_train_sub == uq] = int(i)


for i, uq in enumerate(y_train_sub_uq):
    map_subclass[int(i)] = uq
    y_test_sub[y_test_sub == uq] = int(i)


map_subclass, map_superclass


y_train = np.array(y_train, dtype = float)
y_train = torch.from_numpy(y_train).to(device)
y_train_sub = np.array(y_train_sub, dtype = float)
y_train_sub = torch.from_numpy(y_train_sub).to(device)
y_train.shape, y_train_sub.shape


y_train[:5], y_train_sub[:5]


map_superclass = {0: 'CD', 1: 'HYP', 2: 'MI', 3: 'NORM', 4: 'STTC'}


for idx, label in map_superclass.items():
    y_test[y_test==label] = idx
y_test = np.array(y_test, dtype = float)
y_test = torch.from_numpy(y_test).to(device)
y_test.shape


y_test_sub = np.array(y_test_sub, dtype = float)
y_test_sub = torch.from_numpy(y_test_sub).to(device)
y_test.shape, y_test_sub.shape


gc.collect()
torch.cuda.empty_cache()

X_train = torch.from_numpy(X_train).to(device)
X_train_hr = torch.from_numpy(X_train_hr).to(device)
X_test = torch.from_numpy(X_test).to(device)
X_test_hr = torch.from_numpy(X_test_hr).to(device)
X_train.shape


ch = 1
data = X_test[0, ch, :]
data_hr = X_test_hr[0, ch, :]
data = data.cpu().numpy()
data_hr = X_test_hr[0, ch, :]
data_hr = data_hr.cpu().numpy()
fs_lr = 50
fs_hr = 500


def resample_signal(data, fs=50, nchs = 12, fin = 100):

    data = data.cpu()

    secs = data.shape[-1]/(fin)
    size = int(fs*secs)

    resampled_data = []
    for ch in range(nchs):
        temp = scipy.signal.resample(x=data[ch, :], num=size)
        resampled_data.append(torch.from_numpy(temp))

    resampled_data = torch.stack(resampled_data)

    return resampled_data


X_train.shape


temp = []
for i, signal in enumerate(X_train):
    print(i, end = "\r")
    signal = resample_signal(signal)
    temp.append(myfilter(0.5, signal.cpu(),  powerline = None, fs = fs_lr))

temp = torch.stack(temp)
temp = torch.unsqueeze(temp, dim = 1)
temp = temp.type(torch.FloatTensor).to(device)
X_train = temp
print("")

gc.collect()
torch.cuda.empty_cache()
temp = torch.zeros_like(X_train_hr.cpu())
for i, signal in enumerate(X_train_hr):
    print(i, end = "\r")
    temp[i, :, :] = myfilter_hr(0.5, 150, signal.cpu(), powerline = 50, fs = fs_hr)
temp = torch.unsqueeze(temp, dim = 1)
temp = temp.type(torch.FloatTensor).to(device)
X_train_hr = temp
print("")

gc.collect()
torch.cuda.empty_cache()
temp = []
for i, signal in enumerate(X_test):
    print(i, end = "\r")
    signal = resample_signal(signal) #100 to 50 Hz
    temp.append(myfilter(0.5, signal.cpu(),  powerline = None, fs = fs_lr))

temp = torch.stack(temp)
temp = torch.unsqueeze(temp, dim = 1)
temp = temp.type(torch.FloatTensor).to(device)
X_test = temp
print("")

gc.collect()
torch.cuda.empty_cache()
temp = torch.zeros_like(X_test_hr.cpu())
for i, signal in enumerate(X_test_hr):
    print(i, end = "\r")
    temp[i, :, :] = myfilter_hr(0.5, 150, signal.cpu(), powerline = 50, fs = fs_hr)

temp = torch.unsqueeze(temp, dim = 1)
temp = temp.type(torch.FloatTensor).to(device)
X_test_hr = temp
print("")


map_superclass_rev


label = "MI"
uq = map_superclass_rev[label]
idxs = np.argwhere(y_test.cpu().numpy() == int(uq)).flatten()
test_lr = torch.squeeze(X_test[idxs], dim = 1)
test_hr = torch.squeeze(X_test_hr[idxs], dim = 1)
torch.save(test_lr, "test_lr_MI_50.pt")
torch.save(test_hr, "test_hr_MI.pt")


#y_train = np.array(y_train, dtype = int)
#y_train = torch.from_numpy(y_train).float().to(device)
y_train


#y_train_sub = np.array(y_train_sub, dtype = int)
#y_train_sub = torch.from_numpy(y_train_sub).float().to(device)
y_train_sub


X_train.shape, y_train.shape, y_train_sub.shape


X_test.shape, y_test.shape, y_test.shape


y = [elem for elem in list(X_train[0, 0, 0, :].cpu())]
sig = torch.from_numpy(X[0])
sig = resample_signal(sig, fs = 50)
y_or = [elem for elem in list(sig[ch, :])]
n = len(y)
x = np.arange(0, n, 1)
%matplotlib inline
plt.plot(x, y, "g", label = "Filtered")
plt.plot(x, y_or, "r", label = "Not Filtered")
plt.legend()


from scipy import interpolate

plt.figure(figsize = (20, 10))
idx = 200
signal = X_test[idx].cpu()
signal_hr = X_test_hr[idx].cpu()
ch = 0
signal_ch = signal[0, ch]
signal_hr_ch = signal_hr[0, ch]

fs_lr = 100
fs_hr = 500
t_low_res = np.arange(0, 10, 1/fs_lr)
t_high_res = np.arange(0, 10, 1/fs_hr)  # 500 Hz sampling rate

print(signal_ch.shape, t_low_res.shape)
f_interp = interpolate.interp1d(t_low_res, signal_ch, kind="cubic", fill_value="extrapolate")
signal_up_ch = f_interp(t_high_res)

plt.plot(signal_up_ch, label = "LR")
plt.plot(signal_hr_ch, label = "HR")
plt.legend()


plt.figure(figsize = (20, 10))
sig = torch.from_numpy(X[0])
sig = resample_signal(sig, fs = 50, fin = 100)
sig = resample_signal(sig, fs = 500, fin = 50)
sig_hr = X_hr[0]
plt.plot(sig[0, :], label = "lr")
plt.plot(sig_hr[0, :], label = "hr")
plt.plot(sig[0, :] - sig_hr[0, :], label = "diff")
plt.legend()





uqs = torch.unique(y_train.cpu())
dict_train_data = {}
dict_train_data_hr = {}
dict_test_data = {}
dict_test_data_hr = {}

for uq in uqs:

    print(int(uq), ":", map_superclass[int(uq)])
    idxs = np.argwhere(y_train.cpu().numpy() == int(uq)).flatten()
    dict_train_data[map_superclass[int(uq)]] = torch.squeeze(X_train[idxs], dim = 1)
    dict_train_data_hr[map_superclass[int(uq)]] = torch.squeeze(X_train_hr[idxs], dim = 1)

    idxs = np.argwhere(y_test.cpu().numpy() == int(uq)).flatten()
    dict_test_data[map_superclass[int(uq)]] = torch.squeeze(X_test[idxs], dim = 1)
    dict_test_data_hr[map_superclass[int(uq)]] = torch.squeeze(X_test_hr[idxs], dim = 1)


uqs = torch.unique(y_train_sub.cpu())
dict_train_data_sub = {}
dict_train_data_sub_hr = {}
dict_test_data_sub = {}
dict_test_data_sub_hr = {}

for uq in uqs:

    print(int(uq), ":", map_subclass[int(uq)])
    idxs = np.argwhere(y_train_sub.cpu().numpy() == int(uq)).flatten()
    dict_train_data_sub[map_subclass[int(uq)]] = torch.squeeze(X_train[idxs], dim = 1).cpu()
    dict_train_data_sub_hr[map_subclass[int(uq)]] = torch.squeeze(X_train_hr[idxs], dim = 1).cpu()

    idxs = np.argwhere(y_test_sub.cpu().numpy() == int(uq)).flatten()
    dict_test_data_sub[map_subclass[int(uq)]] = torch.squeeze(X_test[idxs], dim = 1).cpu()
    dict_test_data_sub_hr[map_subclass[int(uq)]] = torch.squeeze(X_test_hr[idxs], dim = 1).cpu()


for key, tensor in dict_train_data.items():
    print(key, ":", tensor.shape)


map_subclass


for key, tensor in dict_train_data_sub.items():
    print(key, ":", tensor.shape)


fs = 50
windows_test, windows_test_sub = split_windows(X_test, y_test_sub, width = fs*5, stride = fs*5)
fs = 500
windows_test_hr, windows_test_sub = split_windows(X_test_hr, y_test_sub, width = fs*5, stride = fs*5)

pt_data_path = os.getcwd() + os.sep + "pt_data" + os.sep
torch.save(windows_test, pt_data_path+"X_test_unf.pt")
torch.save(windows_test_hr, pt_data_path+"X_test_unf_hr.pt")


windows_test_hr.shape, X_test_hr.shape


fs = 50
windows_test, windows_test_labels = split_windows(X_test, y_test, width = fs*5, stride = fs*5)
fs = 500
windows_test_hr, windows_test_labels = split_windows(X_test_hr, y_test, width = fs*5, stride = fs*5)


fs = 50
windows_train, windows_train_sub = split_windows(X_train, y_train_sub, width = fs*5, stride = fs*5)
fs = 500
windows_train_hr, windows_train_sub = split_windows(X_train_hr, y_train_sub, width = fs*5, stride = fs*5)


windows_train_hr.shape, X_train_hr.shape


fs = 50
windows_train, windows_train_labels = split_windows(X_train, y_train, width = fs*5, stride = fs*5)
fs = 500
windows_train_hr, windows_train_labels = split_windows(X_train_hr, y_train, width = fs*5, stride = fs*5)


pt_data_path = os.getcwd() + os.sep + "pt_data" + os.sep + "subclasses"

filename = pt_data_path+ os.sep + "y_test_sup.pt"
torch.save(windows_test_labels, filename)
filename = pt_data_path+ os.sep + "y_test_sub.pt"
torch.save(windows_test_sub, filename)
filename = pt_data_path+ os.sep + "y_train_sup.pt"
torch.save(windows_train_labels, filename)
filename = pt_data_path+ os.sep + "y_train_sub.pt"
torch.save(windows_train_sub, filename)


dict_windows_train = {}
dict_windows_train_hr = {}
dict_windows_test = {}
dict_windows_test_hr = {}

for i, (label, tensor) in enumerate(dict_train_data.items()):

    print(label)
    n = len(tensor)
    labels = [i]*n
    labels = torch.FloatTensor(labels)
    fs = 50
    windows_data, windows_labels = split_windows(tensor, labels, width = fs*5, stride = fs*5)
    #windows_data = torch.unsqueeze(tensor, dim = 1)
    windows_labels = labels
    dict_windows_train[label] = windows_data.to(device)

    tensor_hr = dict_train_data_hr[label]
    fs = 500
    windows_data, windows_labels = split_windows(tensor_hr, labels, width = fs*5, stride = fs*5)


    dict_windows_train_hr[label] = windows_data.to(device)

for i, (label, tensor) in enumerate(dict_test_data.items()):

    print(label)
    n = len(tensor)
    labels = [i]*n
    labels = torch.FloatTensor(labels)
    fs = 50
    windows_data, windows_labels = split_windows(tensor, labels, width = fs*5, stride = fs*5)
    #windows_data = torch.unsqueeze(tensor, dim = 1)
    windows_labels = labels
    dict_windows_test[label] = windows_data.to(device)

    tensor_hr = dict_test_data_hr[label]
    fs = 500
    windows_data, windows_labels = split_windows(tensor_hr, labels, width = fs*5, stride = fs*5)

    dict_windows_test_hr[label] = windows_data.to(device)


dict_windows_train_hr["MI"].shape


dict_windows_train_sub = {}
dict_windows_train_sub_hr = {}
dict_windows_test_sub = {}
dict_windows_test_sub_hr = {}

gc.collect()
torch.cuda.empty_cache()
for i, (label, tensor) in enumerate(dict_train_data_sub.items()):

    print(label)
    n = len(tensor)
    labels = [i]*n*2
    labels = torch.FloatTensor(labels)
    fs = 50
    windows_data, windows_labels = split_windows(tensor, labels, width = fs*5, stride =  fs*5)
    #windows_data = torch.unsqueeze(tensor, dim = 1)
    windows_labels = labels
    dict_windows_train_sub[label] = windows_data#.to(device)

    fs = 500
    tensor_hr = dict_train_data_sub_hr[label]
    #windows_data = torch.unsqueeze(tensor_hr, dim = 1)
    windows_labels = labels
    windows_data, windows_labels = split_windows(tensor_hr, labels, width = fs*5, stride =  fs*5)
    dict_windows_train_sub_hr[label] = windows_data#.to(device)

for i, (label, tensor) in enumerate(dict_test_data_sub.items()):

    print(label)
    n = len(tensor)
    labels = [i]*n*2
    labels = torch.FloatTensor(labels)
    #windows_data = torch.unsqueeze(tensor, dim = 1)
    windows_labels = labels
    fs = 50
    windows_data, windows_labels = split_windows(tensor, labels, width = fs*5, stride =  fs*5)
    dict_windows_test_sub[label] = windows_data#.to(device)

    tensor_hr = dict_test_data_sub_hr[label]
    #windows_data = torch.unsqueeze(tensor_hr, dim = 1)
    windows_labels = labels
    fs = 500
    windows_data, windows_labels = split_windows(tensor_hr, labels, width = fs*5, stride =  fs*5)
    dict_windows_test_sub_hr[label] = windows_data#.to(device)


from random import choice

n = dict_test_data["NORM"].shape[0]
idxs = np.arange(n)
ch = 0
idx = choice(idxs)
signal = dict_test_data["NORM"][idx]
signal_hr = dict_test_data_hr["NORM"][idx]
fig, axs = plt.subplots(2, 1, figsize = (10, 8))
axs[0].plot(signal[ch, :].cpu(), "g")
axs[1].plot(signal_hr[ch, :].cpu(), "b")


import gc
gc.collect()
torch.cuda.empty_cache()


for label, tensor in dict_windows_train.items():
    print(label, ":", tensor.shape)


map_superclass_rev = {value: key for key, value in map_superclass.items()}
map_superclass_rev


pt_data_path = os.getcwd() + os.sep + "pt_data"
for label, data in dict_windows_train.items():

    print(label)
    filename = pt_data_path+ os.sep + "train_{}_50.pt".format(label)
    torch.save(data, filename)

for label, data in dict_windows_train_hr.items():

    print(label)
    filename = pt_data_path+ os.sep + "train_{}_hr.pt".format(label)
    torch.save(data, filename)


for label, data in dict_windows_test.items():

    print(label)
    filename = pt_data_path+ os.sep + "test_{}_50.pt".format(label)
    torch.save(data, filename)

for label, data in dict_windows_test_hr.items():

    print(label)
    filename = pt_data_path+ os.sep + "test_{}_hr.pt".format(label)
    torch.save(data, filename)














#signal 3d visualization

import numpy as np
import matplotlib.pyplot as plt
from matplotlib import rcParams

# 3d plot
fig = plt.figure(figsize = (20, 40))
plt.figure(facecolor='white')#background

signal = dict_windows_train["MI"][0, 0].cpu()
n = signal.shape[-1]
nchs = signal.shape[-2]
chs = np.arange(0, nchs, 1)
t = np.arange(0, n, 1)
ax = fig.add_subplot(projection='3d')

for ch in chs:
    signal_ch = signal[ch, :]
    ax.plot(t, signal_ch, ch, zdir = "y")


ax.set_xlabel("Samples", size = 16)
ax.set_ylabel("Channels", size = 16)
ax.set_zlabel("Amplitude", size = 16)
ax.set_facecolor("white")
rcParams['grid.color'] = 'black'
plt.show()


fig.savefig("lr_3d.png", dpi = 600)








import torch
import os
import neurokit2 as nk


map_superclass_rev = {'CD': 0, 'HYP': 1, 'MI': 2, 'NORM': 3, 'STTC': 4}


labels = list(map_superclass_rev.keys())
dict_windows_test_hr = {}
dict_windows_test_lr = {}
dict_windows_train_lr = {}
dict_windows_train_hr = {}
dict_windows_train_lr_n = {}
dict_windows_test_lr_n = {}

path = os.getcwd()+os.sep+"pt_data"+os.sep
for label in labels:

    filename = path + "test_{}_hr.pt".format(label)
    hr_data = torch.load(filename)
    dict_windows_test_hr[label] = hr_data

    filename = path + "test_{}_50.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_test_lr[label] = lr_data

    filename = path + "train_{}_hr.pt".format(label)
    hr_data = torch.load(filename)
    dict_windows_train_hr[label] = hr_data

    filename = path + "train_{}_50.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_train_lr[label] = lr_data

    filename = path + "test_{}_noisy.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_test_lr_n[label] = lr_data

    filename = path + "train_{}_noisy.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_train_lr_n[label] = lr_data

dict_windows_train = dict_windows_train_lr
dict_windows_test = dict_windows_test_lr


import random

def add_rsp(signal):

    nchs = 12
    duration = 5
    fs = 50

    while True:
        rr_all = np.arange(10, 20, 2)
        rr = random.choice(rr_all)
        #print(rr)
        resp = nk.rsp_simulate(length=fs*duration, sampling_rate = fs, respiratory_rate=rr, method="breathmetrics")

        temp = [torch.from_numpy(resp) for i in range(nchs)]
        resp = torch.from_numpy(np.array(temp))

        if signal.shape == resp.shape:
            break
    noisy_signal = signal.cpu() + resp

    return noisy_signal


def add_emg(signal):

    nchs = 12
    duration = 5
    fs = 50

    bn = random.choice(np.arange(1, 2))
    emg = nk.emg_simulate(length=fs*duration, sampling_rate = fs, burst_number=bn, burst_duration=1)

    temp = [torch.from_numpy(emg) for i in range(nchs)]
    emg = torch.from_numpy(np.array(temp))
    noisy_signal = signal.cpu() + emg
    return noisy_signal


def add_eda(signal):

    nchs = 12
    duration = 5
    fs = 50

    edan = random.choice(np.arange(1, 2))
    eda = nk.eda_simulate(duration = 5, length=fs*duration, sampling_rate = fs, scr_number=edan, drift=-0.5)

    temp = [torch.from_numpy(eda) for i in range(nchs)]
    eda = torch.from_numpy(np.array(temp))
    noisy_signal = signal.cpu() + eda
    return noisy_signal


signal = dict_windows_test_lr[label][0, 0]
signal.shape


noisy_signal = add_rsp(signal)
noise_type = "Respiration Noise"
plt.plot(signal[0, :].cpu(), label = "Clean")
plt.plot(noisy_signal[0, :], label = noise_type)
plt.legend()


noisy_signal = add_emg(signal)
noise_type = "EMG artifact"
plt.plot(signal[0, :].cpu(), label = "Clean")
plt.plot(noisy_signal[0, :], label = noise_type)
plt.legend()


noisy_signal = add_eda(signal)
noise_type = "EDA artifact"
plt.plot(signal[0, :].cpu(), label = "Clean")
plt.plot(noisy_signal[0, :], label = noise_type)
plt.legend()


import matplotlib.pyplot as plt
import torch
import numpy as np

noise_functions = {
    "Respiration Noise": add_rsp,
    "EMG artifact": add_emg,
    "EDA artifact": add_eda
}

fig = plt.figure(figsize = (20, 10))
plt.plot(signal[0, :].cpu(), label = "Clean", linewidth = 4)
for noise_type, noise_function in noise_functions.items():

    noisy_signal = noise_function(signal)
    plt.plot(noisy_signal[0, :], label = noise_type)

plt.legend(fontsize="26")
plt.xticks(fontsize=26)
plt.yticks(fontsize=26)


fig.savefig("ecg_artifact_example.png", dpi = 400)








import os
import torch

labels = list(map_superclass_rev.keys())
dict_windows_test_hr = {}
dict_windows_test_lr = {}
dict_windows_train_lr = {}
dict_windows_train_hr = {}
dict_windows_train_lr_n = {}
dict_windows_test_lr_n = {}

path = os.getcwd()+os.sep+"pt_data"+os.sep
for label in labels:

    if label == "All":
      continue
    print(label)
    filename = path + "test_{}_hr.pt".format(label)
    hr_data = torch.load(filename)
    dict_windows_test_hr[label] = hr_data

    filename = path + "test_{}_50.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_test_lr[label] = lr_data

    filename = path + "train_{}_hr.pt".format(label)
    hr_data = torch.load(filename)
    dict_windows_train_hr[label] = hr_data

    filename = path + "train_{}_50.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_train_lr[label] = lr_data

    filename = path + "test_{}_noisy.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_test_lr_n[label] = lr_data

    filename = path + "train_{}_noisy.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_train_lr_n[label] = lr_data

dict_windows_train = dict_windows_train_lr
dict_windows_test = dict_windows_test_lr


train_noise


for label in labels:
    signals = dict_windows_test_lr[label]
    noisy_signals = torch.zeros_like(signals)
    test_noise = {}

    n = len(signals)
    for i, signal in enumerate(signals):

        print(i+1, "/", n, end="\r")
        idxs =  [0, 1, 2, 3, 4]
        idx = random.choice(idxs)
        if idx >= 3:
            key = "Normal"
            if key in test_noise.keys():
                test_noise[key] += 1
            else:
                test_noise[key] = 0
            noisy_signals[i, 0, :, :] = signal
            continue
        else:
            keys = list(noise_functions.keys())
            key = keys[idx]
            if key in test_noise.keys():
                test_noise[key] += 1
            else:
                test_noise[key] = 0
            noise_function = noise_functions[key]
            signal = torch.squeeze(signal, dim = 0)
            signal = torch.squeeze(signal, dim = 0)
            noisy_signals[i, 0, :, :] = noise_function(signal)
    print("\n")
    dict_windows_test_lr_n[label] = noisy_signals
    torch.save(noisy_signals, "pt_data/test_{}_noisy.pt".format(label))


test_noise





device = "cuda:0"
model = torch.load("models/model_2_nodenoising.pt")
model_d = torch.load("models/model_2_denoising_lrhr.pt")
model = model.to(device)
model_d = model_d.to(device)
#model


def resample_single(to_resample, nchs = 12, size = 5*50):

    resampled_data = np.zeros((nchs, size))
    for ch in range(nchs):
        resampled_data[ch, :] = scipy.signal.resample(x=to_resample[ch, :], num=size)

    return resampled_data


from functions import *


idx = 100#50
signal = dict_windows_test_lr[label][idx, 0]
signal_hr = dict_windows_test_hr[label][idx, 0]
signal.shape, signal_hr.shape


for noise_type, noise_function in noise_functions.items():

    plt.figure(figsize = (20, 10))
    plt.title(noise_type)

    plt.plot(signal_hr[0, :].cpu(), label = "Clean", linewidth = 4)

    noisy_signal = noise_function(signal)
    noisy_signal_u = resample_single(noisy_signal, 12, 5*500)
    plt.plot(noisy_signal_u[0, :], label = "Noisy", linewidth = 0.5)

    noisy_signal_u = torch.from_numpy(noisy_signal_u)
    filtered = myfilter_hr(0.5, 150, noisy_signal_u, powerline = 50)
    filtered = resample_single(filtered, 12, 5*500)
    plt.plot(filtered[0, :], label = "Filtered", linewidth = 0.5)

    input = torch.unsqueeze(noisy_signal, dim = 0)
    input = torch.unsqueeze(input, dim = 0).float().to(device)
    pred = model([input, None, None, None])
    sr_nd = pred[1].cpu().detach().numpy()
    plt.plot(sr_nd[0, :], label = "Our Non-Denoising SR Reconstruction", linewidth = 2)

    pred_d = model_d([input, None, None, None])
    sr_d = pred_d[1].cpu().detach().numpy()
    plt.plot(sr_d[0, :], label = "Our Denoising SR Reconstruction", linewidth = 2)

    plt.legend()


labels = list(dict_windows_train_lr.keys())
labels


import matplotlib.pyplot as plt


idx = 100
ch = 0
dpi = 600
label = "MI"
test_lr_n = dict_windows_train_lr_n[label][idx]
fig = plt.figure(figsize = (20, 10))
plt.plot(test_lr_n[0, ch, :].cpu().detach().numpy(), "g", linewidth = 2)
plt.xticks(fontsize=36)
plt.yticks(fontsize=36)
fig.savefig("lr_example_noise.png", dpi=dpi)


ch = 0
test_hr = dict_windows_train_hr[label][idx]
fig = plt.figure(figsize = (20, 10))
plt.plot(test_hr[0, ch, :].cpu().detach().numpy(), "orange", linewidth = 2)
plt.xticks(fontsize=36)
plt.yticks(fontsize=36)
fig.savefig("hr_example.png", dpi=dpi)


test_lr = dict_windows_train_lr[label][idx]
fig = plt.figure(figsize = (20, 10))
plt.plot(test_lr[0, ch, :].cpu().detach().numpy(), "g", linewidth = 2)
plt.xticks(fontsize=36)
plt.yticks(fontsize=36)
fig.savefig("lr_example.png", dpi=dpi)


sr = model_d([test_lr, None, None, None])[1]
fig = plt.figure(figsize = (20, 10))
plt.plot(sr[ch, :].cpu().detach().numpy(), "blue", linewidth = 2)
plt.xticks(fontsize=36)
plt.yticks(fontsize=36)
fig.savefig("sr_example.png", dpi=dpi)


sr = model_d([test_lr_n, None, None, None])[1]
fig = plt.figure(figsize = (20, 10))
plt.plot(sr[ch, :].cpu().detach().numpy(), "blue", linewidth = 2)
plt.xticks(fontsize=36)
plt.yticks(fontsize=36)
fig.savefig("sr_n_example.png", dpi=dpi)


(test_lr == test_lr_n).all()


rec = model_d([test_lr, None, None, None])[0]
fig = plt.figure(figsize = (20, 10))
plt.plot(rec[ch, :].cpu().detach().numpy(), "r--", linewidth = 2)
plt.xticks(fontsize=36)
plt.yticks(fontsize=36)
fig.savefig("rec_example.png", dpi=dpi)


rec = model_d([test_lr_n, None, None, None])[0]
fig = plt.figure(figsize = (20, 10))
plt.plot(rec[ch, :].cpu().detach().numpy(), "r--", linewidth = 2)
plt.xticks(fontsize=36)
plt.yticks(fontsize=36)
fig.savefig("rec_n_example.png", dpi=dpi)


from scipy import interpolate
def interpolate_single(signal, mode="cubic", fs_lr = 50, fs_hr = 500):
    t_low_res = np.arange(0, 5, 1/fs_lr)
    t_high_res = np.arange(0, 5, 1/fs_hr)  # 500 Hz sampling rate
    f_interp = interpolate.interp1d(t_low_res, signal, kind=mode, fill_value="extrapolate")
    signal_sr = f_interp(t_high_res)
    if isinstance(signal_sr, (np.ndarray, np.generic) ):
        signal_sr = torch.from_numpy(signal_sr)
    return signal_sr


fig = plt.figure(figsize = (10, 5))
label = "STTC"
idx = 100
ch = 0
test_lr_n = dict_windows_train_lr_n[label][idx].to(device)
print(test_lr_n.shape)
test_lrup = interpolate_single(test_lr_n.cpu(), mode="linear")

sr = model_d([test_lr_n, None, None, None])[1]
test_lr_n = test_lr_n[0].cpu()
#plt.plot(test_hr[0, ch, :].cpu().detach().numpy(), "green", label = "High Resolution 500 Hz (target)", linewidth = 3)
plt.plot(test_lrup[0, ch, :], "blue", label = "Low Resolution 50 Hz (input)", linewidth = 1)
plt.plot(sr[ch, :].cpu().detach().numpy(), "red", label = "Super Resolution 500 Hz predicted by DCAE-SR model (output)", linewidth = 2)
plt.xticks(fontsize = 16)
plt.yticks(fontsize = 16)
plt.legend(fontsize = "12")

#fig.savefig("lr_hr_sr.png", dpi = 600)
#fig.savefig("lr_hr.png", dpi = 600)
fig.savefig("lr_sr.png", dpi = 600)


def resample_signal(data, fs=50, nchs = 12, fin = 50):

    data = data.cpu()

    secs = data.shape[-1]/(fin)
    size = int(fs*secs)

    resampled_data = []
    for ch in range(nchs):
        temp = scipy.signal.resample(x=data[ch, :], num=size)
        resampled_data.append(torch.from_numpy(temp))

    resampled_data = torch.stack(resampled_data)

    return resampled_data


len(np.arange(0, 5, 0.002))


import numpy as np

idx = 198
label = "NORM"
lr = dict_windows_train_lr[label][idx]
lr_noise = dict_windows_train_lr_n[label][idx]
hr = dict_windows_train_hr[label][idx]
ch = 0

lr = torch.squeeze(lr, dim = 0)
hr = torch.squeeze(hr, dim = 0).cpu()
lr_noise = torch.squeeze(lr_noise, dim = 0)

lr_up = resample_signal(lr, fs = 500, fin = 50)
lr_noise_up = resample_signal(lr_noise, fs = 500, fin = 50)
time = np.arange(0, 5, 0.002)


fig = plt.figure(figsize = (20, 10))
plt.plot(time, lr_noise_up[ch, :], "r", label = "LR 50 Hz noised", linewidth = 1)
plt.plot(time, lr_up[ch, :], "b", label = "LR 50 Hz clean", linewidth = 1.5)
plt.plot(time, hr[ch, :], "g", label = "HR 500 Hz", linewidth = 2)
plt.legend()


fig.savefig("lrnoised_vs_lr_vs_hr.png", dpi = 600)


import os
import torch

labels = list(map_superclass_rev.keys())
dict_windows_test_hr = {}
dict_windows_test_lr = {}
dict_windows_train_lr = {}
dict_windows_train_hr = {}
dict_windows_train_lr_n = {}
dict_windows_test_lr_n = {}

path = os.getcwd()+os.sep+"pt_data"+os.sep
for label in labels:

    if label == "All":
      continue
    print(label)
    filename = path + "test_{}_hr.pt".format(label)
    hr_data = torch.load(filename)
    dict_windows_test_hr[label] = hr_data

    filename = path + "test_{}_50.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_test_lr[label] = lr_data

    filename = path + "train_{}_hr.pt".format(label)
    hr_data = torch.load(filename)
    dict_windows_train_hr[label] = hr_data

    filename = path + "train_{}_50.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_train_lr[label] = lr_data

    filename = path + "test_{}_noisy.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_test_lr_n[label] = lr_data

    filename = path + "train_{}_noisy.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_train_lr_n[label] = lr_data

dict_windows_train = dict_windows_train_lr
dict_windows_test = dict_windows_test_lr


from matplotlib import gridspec

fig1, axs = plt.subplots(figsize = (20, 10))
ch = 0
idx_signal = 0
idx = -1
ax1 = plt.subplot(3, 2, 1)
ax2 = plt.subplot(3, 2, 2)
ax3 = plt.subplot(3, 2, 3)
ax4 = plt.subplot(3, 2, 4)
ax5 = plt.subplot2grid(shape=(3, 2), loc=(2, 0), colspan=3)
axs = [ax1, ax2, ax3, ax4, ax5]

for i in range(3):
  for j in range(2):
    idx += 1
    print(idx)
    if idx == 5:
      break
    label = labels[idx]
    print(label)
    signal = dict_windows_test_lr[label][idx_signal, 0, ch, :].to("cpu").detach().numpy()
    ax = axs[idx]
    ax.title.set_text('ECG channel {} superclass {}'.format(channels_map[ch], label))
    ax.plot(signal)
plt.savefig("signals_example.png", format='png', dpi=100)


import gc
gc.collect()
torch.cuda.empty_cache()

X_train_lr_n = torch.cat([dict_windows_train_lr_n[label] for label in labels])
X_train_hr = torch.cat([dict_windows_train_hr[label] for label in labels])
X_test_lr_n = torch.cat([dict_windows_test_lr_n[label] for label in labels])
X_test_hr = torch.cat([dict_windows_test_hr[label] for label in labels])
X_train_lr_n.shape, X_test_lr_n.shape


y_train = []
y_test = []
for label, xs in dict_windows_train_lr_n.items():
  n = len(xs)
  label_num = map_superclass_rev[label]
  for i in range(n):
    y_train.append(label_num)

for label, xs in dict_windows_test_lr_n.items():
  n = len(xs)
  label_num = map_superclass_rev[label]
  for i in range(n):
    y_test.append(label_num)

y_train = torch.tensor(y_train)
y_test = torch.tensor(y_test)
y_train.shape, y_test.shape


torch.save(X_train_lr_n, "x_train_lr_noisy.pt")
torch.save(X_train_hr, "x_train_hr_noisy.pt")
torch.save(X_test_lr_n, "x_test_lr_noisy.pt")
torch.save(X_test_hr, "x_test_hr_noisy.pt")


torch.save(y_train, "y_train.pt")
torch.save(X_train_hr, "y_test.pt")





device = "cuda:0"
model_d = torch.load("models/model_2_denoising_lrhr_v2.pt")


idx = 100
ch = 0
label = "STTC"
test_lr_n = dict_windows_train_lr_n[label][idx]
test_lr = dict_windows_train_lr[label][idx]
fig = plt.figure(figsize = (20, 10))
plt.plot(test_lr_n[0, ch, :].cpu().detach().numpy(), "g", linewidth = 2)
#fig.savefig("lr_example.png", dpi=600)


for block in model_d.decoder.decoder:
  block.last_tanh = False
for block in model_d.upsample.decoder:
  block.last_tanh = False


fig = plt.figure(figsize = (20, 10))
sr = model_d([test_lr_n, None])[1]

hr = dict_windows_train_hr[label][idx]
plt.plot(hr[0, ch, :].cpu().detach().numpy(), "g", linewidth = 2)
plt.plot(sr[ch, :].cpu().detach().numpy(), "r--", linewidth = 2)





import pandas as pd
import os

df = pd.read_csv(os.getcwd()+os.sep+"data"+os.sep+"ptbxl_database.csv")
df


df_statements = pd.read_csv(os.getcwd()+os.sep+"data"+os.sep+"scp_statements.csv")
df_statements


df_statements["Unnamed: 0"]


df.columns


df_statements[df_statements["diagnostic_class"] == label]


from ast import literal_eval

def find_patient(df, df_statements, label, number, test = True):

  if test:
    patients = df[df["strat_fold"] == 9]
  else:
    patients = df[df["strat_fold"] != 9]

  scp_codes = df_statements[df_statements["diagnostic_class"] == label]["Unnamed: 0"].values
  print(scp_codes)
  count = 0
  for index, patient in patients.iterrows():
    scp_code = patient["scp_codes"]
    scp_code = literal_eval(scp_code)
    if isinstance(scp_code, dict):
      codes = scp_code.keys()
      #print(codes)
      for code in codes:
        #print(code)
        if code in scp_codes:
          print(code)
          if count == 0:
            count+=1
          else:
            count+=2
          print(count)
          break
      if count >= number:
        return patient

  return patient


label = "STTC"
idx = 100
test_lr = dict_windows_train_lr[label][idx]
patient = find_patient(df, df_statements, label, idx, test = False)
patient


def load_raw_data(filename):
    signal, meta = wfdb.rdsamp(filename)
    signal = signal.T
    return signal, meta


!ls "/content/drive/MyDrive/Colab Notebooks/ECG_SuperResolution/data/PTBXL/rawdata/records100/21000"


import os
cwd = os.getcwd()
sep = os.sep

print(patient)
filename = cwd + sep + "data" + sep + "PTBXL" + sep + "rawdata" + sep + patient[-2]
signal, meta = load_raw_data(filename)
signal, meta


signal.shape


from functions import *
import matplotlib
matplotlib.rc('xtick', labelsize=20)
matplotlib.rc('ytick', labelsize=20)
font = {'family' : '',
        'weight' : 'bold',
        'size'   : 22}

matplotlib.rc('font', **font)


downsignal = resample_signal(torch.from_numpy(signal), fs=50, fin=100)
signal_filt = myfilter(0.05, downsignal)
fs = 50
windows = sliding_window(signal_filt, size = fs*5, stride = fs*5)
#label_num = map_superclass_rev[label]
#windows, _ = split_windows([signal_filt], [label_num], fs*5, stride = fs*5)
#windows = [window.squeeze(dim=0) for window in windows]

plt.figure()
plt.plot(windows[0][ch, :].to("cpu").detach().numpy(), label = "real window 0 LR")
plt.plot(windows[1][ch, :].to("cpu").detach().numpy(), label = "real window 1 LR")
plt.legend()


plt.plot(signal_filt[ch, :])


plt.plot(np.arange(0, 250), windows[0][ch, :].to("cpu").detach().numpy())
plt.plot(np.arange(250, 500), windows[1][ch, :].to("cpu").detach().numpy())
plt.legend()


idx


if idx%2 == 0:
  window_idx = 1
else:
  window_idx = 0
window_idx


plt.plot(windows[window_idx][ch, :].to("cpu").detach().numpy(), label = "real window {} LR".format(window_idx))
plt.plot(test_lr[0, ch].to("cpu").detach().numpy(), label = "LR")
plt.legend()


plt.plot(windows[0][ch, :].to("cpu").detach().numpy(), label = "real window 0 LR")
plt.plot(test_lr[0, ch].to("cpu").detach().numpy(), label = "LR")
plt.legend()


plt.figure()
plt.plot(windows[1][ch, :].to("cpu").detach().numpy(), label = "real window 1 LR")
plt.plot(test_lr[0, ch].to("cpu").detach().numpy(), label = "LR")
plt.legend()


"""
end = False
filenames = df["filename_lr"].values
for i, filename in enumerate(filenames):
  print("\r ", i, "/", len(filenames), end = "")
  filepath = cwd + sep + "data" + sep + "PTBXL" + sep + "rawdata" + sep + filename
  signal, meta = load_raw_data(filepath)
  downsignal = resample_signal(torch.from_numpy(signal), fs=50, fin=100)
  signal_filt = myfilter(0.05, downsignal)
  windows = sliding_window(signal_filt, size = 250, stride = 250)
  windows = torch.from_numpy(np.array(windows)).to(device)
  for window_idx, window in enumerate(windows):
    if torch.equal(window, test_lr):
      end = True
      break
    del window
  if end:
    break
  else:
    del signal
    del meta
    del downsignal
    del signal_filt
    del windows
filename, signal_filt.shape, window_idx, meta
"""





from mpl_toolkits.axes_grid1.inset_locator import mark_inset, inset_axes
from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset
from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar

idx = 100
label = "MI"

to_predict_lr = dict_windows_test_lr_n[label][idx][0, :, :]
to_predict_hr = dict_windows_test_hr[label][idx][0, :, :]

channel = "All Channels"
fig, axs = plt.subplots(2, figsize=(20, 20))
if channel == "All Channels":
  channel_m = channel
else:
  channel_m = channels_map[channel]
#fig.suptitle("Super resoluted ECG signal, channel {}".format(channel_m), fontsize = 36)


model = model.to(device)
model.eval()
pred = model([to_predict_lr.to(device), None, None, None])
n1 = to_predict_lr.shape[-1]
t1 = np.arange(0, n1, 1)
sig_or = torch.squeeze(to_predict_lr).cpu().detach().numpy()
sig_sr = torch.squeeze(pred[1]).cpu().detach().numpy()
n2 = sig_sr.shape[-1]
t2 = np.arange(0, n2, 1)

for i in range(2):

    ax = axs[i]

    if i == 1:
        t = t2
        title = "Super Resolution"
        if channel != "All Channels":
            y = sig_sr[:]
        else:
            y = sig_sr[0, :]
        axins = inset_axes(ax, 2.5, 2.5, loc=1, bbox_to_anchor=(.3, 0.5),bbox_transform=fig.transFigure)
        color = "orange"
    else:
        t = t1
        title = "Original Signal"
        if channel != "All Channels":
            y = sig_or[:]
        else:
            y = sig_or[0, :]
        axins = inset_axes(ax, 2.5, 2.5, loc=2, bbox_to_anchor=(.25, 0.9),bbox_transform=fig.transFigure)
        color = "g"

    ax.plot(t, y, color)
    ax.title.set_text(title)
    ax.title.set_size(32)

    if i == 0:
        i1, i2 = 70, 130# specify the limits
    else:
        i1, i2 = 70*10, 130*10

    axins.plot(t[i1:i2], y[i1:i2], color)

    axins.set_xlim(t[i1], t[i2]) # apply the x-limits
    axins.set_ylim(min(y), max(y)) # apply the y-limits

    mark_inset(ax, axins, loc1=1, loc2=3, fc="none", ec="0.5")

plt.xticks(fontsize = 22)
plt.yticks(fontsize = 22)
plt.show()


fig.savefig("super_resolution_zoom.jpg", dpi=600)






