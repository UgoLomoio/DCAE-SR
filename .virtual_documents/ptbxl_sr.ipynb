in_colab = False
try:
    import google.colab
    in_colab = True
except:
    in_colab = False
in_colab


if in_colab:
  !pip install neurokit2
  !pip install torchinfo
  !pip install pytorch_lightning
  !pip install wfdb
  #!pip install ssqueezepy
  !pip install pycwt
  #!pip install matplotlib==3.8
  #!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118


import torch
from torch import optim, nn
from IPython.display import clear_output
from torchinfo import summary
import neurokit2 as nk
from sklearn.decomposition import PCA
from plotly import graph_objects as go
import os
import pywt as pw
from math import ceil
import cv2
from matplotlib import cm
from matplotlib import rcParams
import pytorch_lightning as pl
import imageio
import gc
import collections
from pytorch_lightning.loggers import Logger
from pytorch_lightning.loggers.logger import rank_zero_experiment
from pytorch_lightning.utilities import rank_zero_only
import scipy
import pandas as pd
import wfdb
import matplotlib.pyplot as plt
import ast
import os
import warnings
import numpy as np
import math
from torch.utils.data import DataLoader, Dataset
import cv2 as cv
from scipy.signal import butter, lfilter, iirnotch

gc.collect()
with torch.no_grad():
    torch.cuda.empty_cache()

warnings.simplefilter(action='ignore', category=FutureWarning)
rcParams['font.weight'] = 'bold'
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"


channels = ["I", "II", "III", "aVL", "aVR", "aVF", "V1", "V2", "V3", "V4", "V5", "V6" ]
channels_map = {idx: channel for idx, channel in enumerate(channels)}


!python --version


torch.__version__


torch.cuda.is_available()


device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")


%matplotlib inline


map_superclass_rev = {'CD': 0, 'HYP': 1, 'MI': 2, 'NORM': 3, 'STTC': 4}


if in_colab:
  from google.colab import drive
  drive.mount("/content/drive/", force_remount = True)
  %cd "drive/MyDrive/Colab Notebooks/ECG_SuperResolution"


cwd = os.getcwd() + os.sep
path = cwd+"data"+os.sep+"PTBXL"+os.sep+"rawdata"+os.sep#"data\\1d\\PTBXL"+os.sep #your dataset path here
filename = path + "ptbxl_database.csv"
df = pd.read_csv(filename, sep=",", index_col="ecg_id")
df.head(20)


n, m = df.shape
n, m


columns = df.columns
map_columns = {column: i for i, column in enumerate(columns)}
map_columns


from functions import *


def resample_signal(data, fs=50, nchs = 12, fin = 50):

    data = data.cpu()

    secs = data.shape[-1]/(fin)
    size = int(fs*secs)

    resampled_data = []
    for ch in range(nchs):
        temp = scipy.signal.resample(x=data[ch, :], num=size)
        resampled_data.append(torch.from_numpy(temp))

    resampled_data = torch.stack(resampled_data)

    return resampled_data


device = "cuda:0"
model_d = torch.load("models/model_2_denoising_lrhr_v2.pt").to(device)
for block in model_d.decoder.decoder:
  block.last_tanh = False
for block in model_d.upsample.decoder:
  block.last_tanh = False





labels = list(map_superclass_rev.keys())
dict_windows_test_hr = {}
dict_windows_test_lr = {}
dict_windows_train_lr = {}
dict_windows_train_hr = {}
dict_windows_train_lr_n = {}
dict_windows_test_lr_n = {}

path = os.getcwd()+os.sep+"pt_data"+os.sep
for label in labels:

    if label == "All":
      continue
    filename = path + "test_{}_hr.pt".format(label)
    hr_data = torch.load(filename)
    dict_windows_test_hr[label] = hr_data

    filename = path + "test_{}_50.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_test_lr[label] = lr_data

    filename = path + "train_{}_hr.pt".format(label)
    hr_data = torch.load(filename)
    dict_windows_train_hr[label] = hr_data

    filename = path + "train_{}_50.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_train_lr[label] = lr_data

    filename = path + "test_{}_noisy.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_test_lr_n[label] = lr_data

    filename = path + "train_{}_noisy.pt".format(label)
    lr_data = torch.load(filename)
    dict_windows_train_lr_n[label] = lr_data

dict_windows_train = dict_windows_train_lr
dict_windows_test = dict_windows_test_lr


labels


fig = plt.figure(figsize = (20, 10))
label = "HYP"
idx = 250
ch = 0
test_lr_n = dict_windows_train_lr[label][idx]
sr = model_d([test_lr_n, None])[1]

hr = dict_windows_train_hr[label][idx]
plt.plot(hr[0, ch, :].cpu().detach().numpy(), "g", label = "HR", linewidth = 2)
plt.plot(sr[ch, :].cpu().detach().numpy(), "r", label = "SR", linewidth = 2)
plt.legend()





import pandas as pd
import os

df = pd.read_csv(os.getcwd()+os.sep+"data"+os.sep+"ptbxl_database.csv")
df


df_statements = pd.read_csv(os.getcwd()+os.sep+"data"+os.sep+"scp_statements.csv")
df_statements


df_statements["Unnamed: 0"]


df.columns


df_statements[df_statements["diagnostic_class"] == label]


from ast import literal_eval

def find_patient(df, df_statements, label, number, test = True):

  if test:
    patients = df[df["strat_fold"] == 9]
  else:
    patients = df[df["strat_fold"] != 9]

  scp_codes = df_statements[df_statements["diagnostic_class"] == label]["Unnamed: 0"].values
  print(scp_codes)
  count = 0
  for index, patient in patients.iterrows():
    scp_code = patient["scp_codes"]
    scp_code = literal_eval(scp_code)
    if isinstance(scp_code, dict):
      codes = scp_code.keys()
      #print(codes)
      for code in codes:
        #print(code)
        if code in scp_codes:
          print(code)
          if count == 0:
            count+=1
          else:
            count+=2
          print(count)
          break
      if count >= number:
        return patient

  return patient


label = "STTC"
idx = 100
test_lr = dict_windows_train_lr[label][idx]
patient = find_patient(df, df_statements, label, idx, test = False)
patient


def load_raw_data(filename):
    signal, meta = wfdb.rdsamp(filename)
    signal = signal.T
    return signal, meta


!ls "/content/drive/MyDrive/Colab Notebooks/ECG_SuperResolution/data/PTBXL/rawdata/records100/21000"


import os
cwd = os.getcwd()
sep = os.sep

print(patient)
filename = cwd + sep + "data" + sep + "PTBXL" + sep + "rawdata" + sep + patient[-2]
signal, meta = load_raw_data(filename)
signal, meta


signal.shape


from functions import *
import matplotlib
matplotlib.rc('xtick', labelsize=20)
matplotlib.rc('ytick', labelsize=20)
font = {'family' : '',
        'weight' : 'bold',
        'size'   : 22}

matplotlib.rc('font', **font)


downsignal = resample_signal(torch.from_numpy(signal), fs=50, fin=100)
signal_filt = myfilter(0.05, downsignal)
fs = 50
windows = sliding_window(signal_filt, size = fs*5, stride = fs*5)
#label_num = map_superclass_rev[label]
#windows, _ = split_windows([signal_filt], [label_num], fs*5, stride = fs*5)
#windows = [window.squeeze(dim=0) for window in windows]

plt.figure()
plt.plot(windows[0][ch, :].to("cpu").detach().numpy(), label = "real window 0 LR")
plt.plot(windows[1][ch, :].to("cpu").detach().numpy(), label = "real window 1 LR")
plt.legend()


plt.plot(signal_filt[ch, :])


plt.plot(np.arange(0, 250), windows[0][ch, :].to("cpu").detach().numpy())
plt.plot(np.arange(250, 500), windows[1][ch, :].to("cpu").detach().numpy())
plt.legend()


idx


if idx%2 == 0:
  window_idx = 1
else:
  window_idx = 0
window_idx


plt.plot(windows[window_idx][ch, :].to("cpu").detach().numpy(), label = "real window {} LR".format(window_idx))
plt.plot(test_lr[0, ch].to("cpu").detach().numpy(), label = "LR")
plt.legend()


plt.plot(windows[0][ch, :].to("cpu").detach().numpy(), label = "real window 0 LR")
plt.plot(test_lr[0, ch].to("cpu").detach().numpy(), label = "LR")
plt.legend()


plt.figure()
plt.plot(windows[1][ch, :].to("cpu").detach().numpy(), label = "real window 1 LR")
plt.plot(test_lr[0, ch].to("cpu").detach().numpy(), label = "LR")
plt.legend()








df.columns


patients_id = df.patient_id.values
patients_id


#for patient_id in patients_id:
double_signal_patient = {}
for i, patient_id in enumerate(patients_id):
  print("\r", i+1, "/", len(patients_id), end = "")
  n, m = df[df["patient_id"] == patient_id].shape
  if n > 1:
    double_signal_patient[patient_id] = df[df["patient_id"] == patient_id]["filename_hr"].values


double_signal_patient


df_statements.columns, df.columns


n = len(double_signal_patient.keys())
n


from collections import Counter

labels_patient = {}
for i, patient_id in enumerate(list(double_signal_patient.keys())):

    print("\r", i+1, "/", n, end = "")
    if patient_id not in labels_patient.keys():
      labels_patient[patient_id] = []

    scp_codes = df[df["patient_id"] == patient_id]["scp_codes"]
    for scp_codes_signal in scp_codes:
      scp_codes_signal = literal_eval(scp_codes_signal)
      temp_labels = []
      for scp_code in list(scp_codes_signal.keys()):
        temp_label =  df_statements[df_statements["Unnamed: 0"] == scp_code]["diagnostic_subclass"].values
        temp_labels.append(temp_label)
      temp_labels = np.array(temp_labels)
      counter = Counter(temp_labels.flat).most_common(1)
      label = counter[0][0]
      labels_patient[patient_id].append(label)


df_statements["diagnostic_subclass"].isna().sum()


df_statements[df_statements["diagnostic_subclass"].isna() == True]


len(double_signal_patient[9740.0]), len(labels_patient[9740.0])


labels_patient


earlydet_patients = {}

for patient_id, labels in labels_patient.items():

  found_norm = False
  found_abn = False
  for label in labels:
    if label == "NORM":
      if not found_abn:
        found_norm = True
    elif not isinstance(label, float):
      found_abn = True

  if found_norm and found_abn:
    earlydet_patients[patient_id] = labels


len(earlydet_patients.keys())


earlydet_patients
